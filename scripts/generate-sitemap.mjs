/**
 * Sitemap Generator Script
 *
 * Generates a static sitemap.xml file for SEO and LLM crawler optimization.
 * Run with: node scripts/generate-sitemap.mjs
 * Or via npm: npm run generate:sitemap
 */

import fs from 'fs'
import path from 'path'
import matter from 'gray-matter'
import { fileURLToPath } from 'url'

const __filename = fileURLToPath(import.meta.url)
const __dirname = path.dirname(__filename)

const SITE_URL = process.env.NEXT_PUBLIC_SITE_URL || 'https://example.com'
const ROOT_DIR = path.join(__dirname, '..')
const BLOG_DIR = path.join(ROOT_DIR, 'content', 'blog')
const PUBLIC_DIR = path.join(ROOT_DIR, 'public')

function getBlogPosts() {
  if (!fs.existsSync(BLOG_DIR)) {
    console.log('No blog directory found, skipping blog posts')
    return []
  }

  const files = fs.readdirSync(BLOG_DIR)
  const posts = []

  for (const file of files) {
    if (!file.endsWith('.mdx') && !file.endsWith('.md')) continue

    const filePath = path.join(BLOG_DIR, file)
    const content = fs.readFileSync(filePath, 'utf8')
    const { data } = matter(content)

    const slug = file.replace(/\.mdx?$/, '')
    const date = data.lastModified || data.date || new Date().toISOString()

    posts.push({
      slug,
      date: new Date(date).toISOString(),
      category: data.category || 'Uncategorized',
      tags: data.tags || [],
    })
  }

  return posts.sort((a, b) => new Date(b.date).getTime() - new Date(a.date).getTime())
}

function generateSitemapXml(entries) {
  const urlEntries = entries
    .map(
      (entry) => `  <url>
    <loc>${entry.url}</loc>
    <lastmod>${entry.lastmod}</lastmod>
    <changefreq>${entry.changefreq}</changefreq>
    <priority>${entry.priority.toFixed(1)}</priority>
  </url>`
    )
    .join('\n')

  return `<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9"
        xmlns:news="http://www.google.com/schemas/sitemap-news/0.9"
        xmlns:xhtml="http://www.w3.org/1999/xhtml"
        xmlns:image="http://www.google.com/schemas/sitemap-image/1.1">
${urlEntries}
</urlset>`
}

function main() {
  console.log('ðŸ—ºï¸  Generating sitemap.xml...\n')

  const entries = []
  const now = new Date().toISOString()

  // Static pages
  const staticPages = [
    { path: '', changefreq: 'weekly', priority: 1.0 },
    { path: '/blog', changefreq: 'daily', priority: 0.9 },
  ]

  for (const page of staticPages) {
    entries.push({
      url: `${SITE_URL}${page.path}`,
      lastmod: now,
      changefreq: page.changefreq,
      priority: page.priority,
    })
  }

  console.log(`âœ… Added ${staticPages.length} static pages`)

  // Blog posts
  const posts = getBlogPosts()
  const categories = new Set()
  const tags = new Set()

  for (const post of posts) {
    entries.push({
      url: `${SITE_URL}/blog/${post.slug}`,
      lastmod: post.date,
      changefreq: 'monthly',
      priority: 0.8,
    })

    categories.add(post.category.toLowerCase())
    post.tags.forEach((tag) => tags.add(tag.toLowerCase()))
  }

  console.log(`âœ… Added ${posts.length} blog posts`)

  // Category pages
  for (const category of categories) {
    entries.push({
      url: `${SITE_URL}/blog/category/${encodeURIComponent(category)}`,
      lastmod: now,
      changefreq: 'weekly',
      priority: 0.6,
    })
  }

  console.log(`âœ… Added ${categories.size} category pages`)

  // Tag pages
  for (const tag of tags) {
    entries.push({
      url: `${SITE_URL}/blog/tag/${encodeURIComponent(tag)}`,
      lastmod: now,
      changefreq: 'weekly',
      priority: 0.5,
    })
  }

  console.log(`âœ… Added ${tags.size} tag pages`)

  // Generate XML
  const xml = generateSitemapXml(entries)

  // Write to public directory
  const sitemapPath = path.join(PUBLIC_DIR, 'sitemap.xml')
  fs.writeFileSync(sitemapPath, xml, 'utf8')

  console.log(`\nðŸ“„ Sitemap written to: ${sitemapPath}`)
  console.log(`ðŸ“Š Total URLs: ${entries.length}`)
  console.log(`ðŸ”— Site URL: ${SITE_URL}`)

  // Also generate a robots.txt if it doesn't exist
  const robotsPath = path.join(PUBLIC_DIR, 'robots.txt')
  if (!fs.existsSync(robotsPath)) {
    const robotsTxt = `# Robots.txt for ${SITE_URL}
# Generated by generate-sitemap.mjs

User-agent: *
Allow: /
Disallow: /api/
Disallow: /dashboard/

# AI Crawlers - Explicitly allowed
User-agent: GPTBot
Allow: /

User-agent: ChatGPT-User
Allow: /

User-agent: Claude-Web
Allow: /

User-agent: ClaudeBot
Allow: /

User-agent: Anthropic-AI
Allow: /

User-agent: PerplexityBot
Allow: /

User-agent: Applebot
Allow: /

User-agent: Google-Extended
Allow: /

Sitemap: ${SITE_URL}/sitemap.xml
`
    fs.writeFileSync(robotsPath, robotsTxt, 'utf8')
    console.log(`ðŸ¤– robots.txt written to: ${robotsPath}`)
  }

  console.log('\nâœ¨ Sitemap generation complete!')
}

main()
